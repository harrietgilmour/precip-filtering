{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local packages\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# Third party packages\n",
    "import iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "import datetime\n",
    "import shutil\n",
    "from six.moves import urllib\n",
    "from pathlib import Path\n",
    "import trackpy\n",
    "from iris.time import PartialDateTime\n",
    "import functions\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed as dd\n",
    "from dask import delayed\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "import tobac #tobac package cloned from https://github.com/tobac-project/tobac.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and set up warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=pd.io.pytables.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions and dictionaries\n",
    "import functions as fnc\n",
    "import dictionaries as dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the datasets\n",
    "mask, precip, tracks = fnc.open_datasets(dic.mask_file, dic.precip_file, dic.tracks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the tracks file\n",
    "tracks = fnc.copy_tracks_file(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the precip columns to tracks\n",
    "tracks = fnc.add_precip_columns(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non track cells from tracks\n",
    "tracks = fnc.remove_non_track_cells(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all of the unique track cells values within the tracks df\n",
    "unique_cells = fnc.find_unique_cells(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of delayed computations for each cell\n",
    "delayed_results = [delayed(fnc.precip_filtering_loop_cell)(cell, tracks, precip, mask, unique_cells, dic.precip_threshold, dic.heavy_precip_threshold, dic.extreme_precip_threshold, dic.s, dic.precip_area, dic.removed_tracks, dic.tracks_filtered_output, dic.tracks_cell_output_dir) for cell in unique_cells]\n",
    "\n",
    "# compute the results in parallel\n",
    "tracks_list = dask.compute(*delayed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the results back into a single dataframe\n",
    "# using a dask dataframe\n",
    "tracks = pd.concat(tracks_list)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
